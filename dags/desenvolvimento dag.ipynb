{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "### IMPORTS.PY ###\n",
    "\n",
    "import requests\n",
    "import time\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import json\n",
    "from typing import Optional\n",
    "import io\n",
    "\n",
    "import boto3\n",
    "from botocore.exceptions import NoCredentialsError\n",
    "\n",
    "from funcoes import gerar_path, get_dados, get_dados_v2, salvar_json, renomear_chaves\n",
    "\n",
    "from airflow import DAG\n",
    "from airflow.operators.python import PythonOperator\n",
    "from airflow.utils.dates import days_ago\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### VARIÁVEIS DO UTILS ###\n",
    "\n",
    "# Toekn de autenticação\n",
    "token = \"c7014553669e9dc53bf808f07a85f3fa0ac0eea3db93451487735b128b8e175e\"\n",
    "\n",
    "# URL para autenticação\n",
    "base_url = \"http://api.olhovivo.sptrans.com.br/v2.1\"\n",
    "auth_parametro = \"Login/Autenticar\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1888\n",
      "Autenticacao realizada com sucesso!\n",
      "Autenticacao realizada com sucesso!\n",
      "Autenticacao realizada com sucesso!\n",
      "Autenticacao realizada com sucesso!\n",
      "Autenticacao realizada com sucesso!\n",
      "Autenticacao realizada com sucesso!\n",
      "Autenticacao realizada com sucesso!\n",
      "Autenticacao realizada com sucesso!\n",
      "Autenticacao realizada com sucesso!\n",
      "Autenticacao realizada com sucesso!\n",
      "Autenticacao realizada com sucesso!\n",
      "Autenticacao realizada com sucesso!\n",
      "Autenticacao realizada com sucesso!\n",
      "Autenticacao realizada com sucesso!\n",
      "Autenticacao realizada com sucesso!\n",
      "Autenticacao realizada com sucesso!\n",
      "Autenticacao realizada com sucesso!\n",
      "Autenticacao realizada com sucesso!\n",
      "Autenticacao realizada com sucesso!\n",
      "Autenticacao realizada com sucesso!\n",
      "Arquivo salvo com sucesso\n"
     ]
    }
   ],
   "source": [
    "# Criando uma sessao\n",
    "session = requests.Session()\n",
    "\n",
    "# Realizando autenticação antes de iniciar requisições\n",
    "path_auth = gerar_path(base_url, auth=auth_parametro, token=token)\n",
    "auth_response = session.post(path_auth)\n",
    "\n",
    "# Fazendo várias requisições com a mesma sessão\n",
    "dados_corredor = get_dados_v2(session, base_url, categoria=\"Corredor\", token=token)\n",
    "dados_empresa = get_dados_v2(session, base_url, categoria=\"Empresa\", token=token)\n",
    "dados_posicao = get_dados_v2(session, base_url, categoria=\"Posicao\", token=token)\n",
    "\n",
    "# Extrair a lista de todas as linhas da posicao\n",
    "lista_linhas = list(set([i['cl'] for i in dados_posicao['l']]))\n",
    "print(len(lista_linhas))\n",
    "\n",
    "### EXTRAIR DADOS DE PREVISAO DE CHEGADA DE CADA LINHA RETORNADA NO JSON DE POSICAO ###\n",
    "dados_previsao = []\n",
    "\n",
    "for i in lista_linhas[:10]: # FILTRANDO APENAS AS PRIMEIRAS 100\n",
    "    previsao_linha = get_dados(session, base_url, categoria=\"Previsao\", metodo=\"Linha\", sufix=\"codigoLinha\", parametro=str(i), token=token)\n",
    "    \n",
    "    # Adiciona o código da linha 'i' ao JSON de previsão retornado\n",
    "    if previsao_linha:  # Verifica se a resposta não é nula\n",
    "        previsao_linha['codigo_linha'] = i  # Adiciona o código da linha ao JSON\n",
    "\n",
    "        # Adiciona a previsão à lista\n",
    "        dados_previsao.append(previsao_linha)\n",
    "\n",
    "\n",
    "### EXTRAIR DADOS DE PARADA DE CADA LINHA RETORNADA NO JSON DE POSICAO ###\n",
    "dados_parada = []\n",
    "\n",
    "for i in lista_linhas[:10]: # FILTRANDO APENAS AS PRIMEIRAS 100\n",
    "    parada_linha = get_dados(session, base_url, categoria=\"Parada\", metodo=\"BuscarParadasPorLinha\", sufix=\"codigoLinha\", parametro=str(i), token=token)\n",
    "    \n",
    "    # Adiciona o código da linha em cada parada retornada\n",
    "    if parada_linha:  # Verifica se há dados de paradas\n",
    "        for parada in parada_linha:\n",
    "            parada['codigo_linha'] = i\n",
    "            \n",
    "        dados_parada.append(parada_linha)\n",
    "\n",
    "\n",
    "# Finalizando a sessão quando não for mais necessária\n",
    "session.close()\n",
    "\n",
    "# Gerar variável para salvar no nome do arquivo\n",
    "agora = datetime.now().strftime(\"%Y-%m-%d_%H%M%S\")\n",
    "\n",
    "# Definindo variáveis para salvar dados no raw do minio\n",
    "#minio_url = \"http://minio:9000\" # QUANDO FOR RODAR NO AIRFLOW\n",
    "minio_url = \"http://localhost:9050\" # QUANDO ESTIVER LOCAL\n",
    "access_key = \"VsbEm45pTDOcC6dVo5Vk\"\n",
    "secret_key = \"4heTCFf5gT2M4xpJYElhbk8h7fo6TVAn7f4yl4gH\"\n",
    "\n",
    "s3_client = boto3.client(\n",
    "    's3',\n",
    "    endpoint_url = minio_url,\n",
    "    aws_access_key_id = access_key,\n",
    "    aws_secret_access_key = secret_key\n",
    ")\n",
    "\n",
    "# Definindo o bucket de destino\n",
    "bucket_name = \"raw\"\n",
    "\n",
    "# Caminhos de cada dado bruto \n",
    "path_posicao = f'/posicao/{agora}.json'\n",
    "path_corredor = f'/corredor/{agora}.json'\n",
    "path_empresa = f'/empresa/{agora}.json'\n",
    "path_previsao = f'/previsao/{agora}.json'\n",
    "path_parada = f'/parada/{agora}.json'\n",
    "\n",
    "# Convertendo o dicionário extraído da API em uma string \n",
    "dados_posicao_s3 = json.dumps(dados_posicao)\n",
    "dados_corredor_s3 = json.dumps(dados_corredor)\n",
    "dados_empresa_s3 = json.dumps(dados_empresa)\n",
    "dados_previsao_s3 = json.dumps(dados_previsao)\n",
    "dados_parada_s3 = json.dumps(dados_parada)\n",
    "\n",
    "# Salvando dados no bucket\n",
    "s3_client.put_object(Bucket=bucket_name, Key=path_posicao, Body=dados_posicao_s3)\n",
    "s3_client.put_object(Bucket=bucket_name, Key=path_corredor, Body=dados_corredor_s3)\n",
    "s3_client.put_object(Bucket=bucket_name, Key=path_empresa, Body=dados_empresa_s3)\n",
    "s3_client.put_object(Bucket=bucket_name, Key=path_previsao, Body=dados_previsao_s3)\n",
    "s3_client.put_object(Bucket=bucket_name, Key=path_parada, Body=dados_parada_s3)\n",
    "\n",
    "print(\"Arquivo salvo com sucesso\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # Trazer nome dos campos com base no catálogo da api\n",
    "    df = pd.read_excel('catálogo api.xlsx', sheet_name=\"Objetos de retorno\")\n",
    "except:\n",
    "    print(\"erro\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRUSTED POSICAO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrar registros onde Categoria e Método = Posicao\n",
    "df_filtrado = df[(df['Categoria'] == 'Posicao') & (df['Métodos'] == 'Posicao')]\n",
    "\n",
    "# Criar o dicionário usando as colunas \"Chave\" e \"Nome Campo\"\n",
    "mapa_chaves = dict(zip(df_filtrado['Chave'], df_filtrado['Nome Campo']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hr': 'hora_referencia_infos',\n",
       " 'l': 'linhas_localizadas',\n",
       " 'c': 'letreiro_completo_linha',\n",
       " 'cl': 'codigo_linha',\n",
       " 'sl': 'sentido_linha',\n",
       " 'lt0': 'letreiro_destino_linha',\n",
       " 'lt1': 'letreiro_origem_linha',\n",
       " 'qv': 'quantidade_veiculos_localizados',\n",
       " 'vs': 'veiculos_localizados',\n",
       " 'p': 'prefixo_veiculo',\n",
       " 'a': 'veiculo_acessivel_pessoas_deficiencia',\n",
       " 'ta': 'horario_universal_localizacao_capturada',\n",
       " 'py': 'latitude_localizada',\n",
       " 'px': 'longitude_localizada'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapa_chaves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrar registros onde Categoria e Método = Posicao\n",
    "filtro_posicao = df[(df['Categoria'] == 'Posicao') & (df['Métodos'] == 'Posicao')]\n",
    "\n",
    "# Criar o dicionário usando as colunas \"Chave\" e \"Nome Campo\"\n",
    "mapa_chaves_posicao = dict(zip(filtro_posicao['Chave'], filtro_posicao['Nome Campo']))\n",
    "\n",
    "# Aplicar função para ajustar nome dos dados\n",
    "dados_posicao_renomeados = renomear_chaves(dados_posicao, mapa_chaves_posicao)\n",
    "\n",
    "# Transformar o dicionário renomeado em um DataFrame\n",
    "linhas_localizadas = dados_posicao_renomeados['linhas_localizadas']\n",
    "\n",
    "# Extraindo informações dos veículos dentro de cada linha localizada\n",
    "veiculos_lista = []\n",
    "for linha in linhas_localizadas:\n",
    "    for veiculo in linha['veiculos_localizados']:\n",
    "        # Adicionando detalhes da linha junto com os veículos\n",
    "        veiculo_completo = veiculo.copy()  # Copia as informações do veículo\n",
    "        veiculo_completo.update({\n",
    "            'hora_referencia_infos': dados_posicao_renomeados['hora_referencia_infos'],\n",
    "            'letreiro_completo': linha['letreiro_completo_linha'],\n",
    "            'codigo_linha': linha['codigo_linha'],\n",
    "            'sentido_linha': linha['sentido_linha'],\n",
    "            'letreiro_destino_linha': linha['letreiro_destino_linha'],\n",
    "            'letreiro_origem_linha': linha['letreiro_origem_linha'],\n",
    "            'quantidade_veiculos_localizados': linha['quantidade_veiculos_localizados']\n",
    "        })\n",
    "        veiculos_lista.append(veiculo_completo)\n",
    "\n",
    "# Criar o DataFrame com todas as informações dos veículos e suas respectivas linhas\n",
    "df_posicao = pd.DataFrame(veiculos_lista)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': '18021D15886162F2',\n",
       "  'HostId': 'dd9025bab4ad464b049177c95eb6ebf374d3b3fd1af9251148b658df7ac2e3e8',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'accept-ranges': 'bytes',\n",
       "   'content-length': '0',\n",
       "   'etag': '\"71d3d2008bb0bf11611932da97aa6d3b\"',\n",
       "   'server': 'MinIO',\n",
       "   'strict-transport-security': 'max-age=31536000; includeSubDomains',\n",
       "   'vary': 'Origin, Accept-Encoding',\n",
       "   'x-amz-id-2': 'dd9025bab4ad464b049177c95eb6ebf374d3b3fd1af9251148b658df7ac2e3e8',\n",
       "   'x-amz-request-id': '18021D15886162F2',\n",
       "   'x-content-type-options': 'nosniff',\n",
       "   'x-ratelimit-limit': '2001',\n",
       "   'x-ratelimit-remaining': '2001',\n",
       "   'x-xss-protection': '1; mode=block',\n",
       "   'date': 'Sat, 26 Oct 2024 21:13:05 GMT'},\n",
       "  'RetryAttempts': 0},\n",
       " 'ETag': '\"71d3d2008bb0bf11611932da97aa6d3b\"'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_posicao = df_posicao.astype(str)\n",
    "\n",
    "csv_buffer = io.StringIO()\n",
    "df_posicao.to_csv(csv_buffer, index=False)\n",
    "\n",
    "\n",
    "# Salvando dados no bucket\n",
    "s3_client.put_object(Bucket=\"trusted\", Key=f'/posicao/{agora}.csv', Body=csv_buffer.getvalue(), ContentType='text/csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRUSTED PREVISAO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrar registros onde Categoria e Método = Previsao\n",
    "filtro_previsao = df[(df['Categoria'] == 'Previsao') & (df['Métodos'] == 'Linha')]\n",
    "\n",
    "# Criar o dicionário usando as colunas \"Chave\" e \"Nome Campo\"\n",
    "mapa_chaves_previsao = dict(zip(filtro_previsao['Chave'], filtro_previsao['Nome Campo']))\n",
    "\n",
    "# Renomear as chaves do JSON usando o mapa_chaves_previsao\n",
    "dados_previsao_renomeados = renomear_chaves(dados_previsao, mapa_chaves_previsao)\n",
    "\n",
    "# Função para transformar o JSON renomeado em DataFrame\n",
    "def json_previsao_para_df(dados_renomeados):\n",
    "    veiculos_lista = []\n",
    "    for previsao in dados_renomeados:\n",
    "        codigo_linha = previsao.get('codigo_linha')  # Código da linha renomeado\n",
    "        hora_referencia = previsao.get('hora_referencia_infos')  # Hora de referência renomeada\n",
    "        for parada in previsao.get('relacao_pontos_parada', []):  # Lista de paradas renomeada\n",
    "            codigo_parada = parada.get('codigo_parada')\n",
    "            nome_parada = parada.get('nome_parada')\n",
    "            latitude_parada = parada.get('latitude_localizada')\n",
    "            longitude_parada = parada.get('longitude_localizada')\n",
    "            \n",
    "            for veiculo in parada.get('veiculos_localizados', []):  # Acessa cada veículo na parada\n",
    "                veiculo_completo = veiculo.copy()\n",
    "                veiculo_completo.update({\n",
    "                    'hora_referencia_infos': hora_referencia,\n",
    "                    'codigo_parada': codigo_parada,\n",
    "                    'nome_parada': nome_parada,\n",
    "                    'latitude_parada': latitude_parada,\n",
    "                    'longitude_parada': longitude_parada,\n",
    "                    'codigo_linha': codigo_linha,\n",
    "                    'latitude_veiculo': veiculo.get('latitude_localizada'),  # Coordenada do veículo renomeada\n",
    "                    'longitude_veiculo': veiculo.get('longitude_localizada')  # Coordenada do veículo renomeada\n",
    "                })\n",
    "                veiculos_lista.append(veiculo_completo)\n",
    "    \n",
    "    # Criar o DataFrame com as informações extraídas\n",
    "    df_previsao = pd.DataFrame(veiculos_lista)\n",
    "    return df_previsao\n",
    "\n",
    "# Transformar os dados renomeados em um DataFrame\n",
    "df_previsao = json_previsao_para_df(dados_previsao_renomeados)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_previsao = df_previsao[[\n",
    "    'codigo_linha',\n",
    "    'hora_referencia_infos',\n",
    "    'codigo_parada',\n",
    "    'nome_parada',\n",
    "    'latitude_parada',\n",
    "    'longitude_parada',\n",
    "    'prefixo_veiculo',\n",
    "    'horario_previsto_chegada_veiculo_na_parada',\n",
    "    'veiculo_acessivel_pessoas_deficiencia',\n",
    "    'horario_universal_localizacao_capturada',\n",
    "    'latitude_veiculo',\n",
    "    'longitude_veiculo'\n",
    "\n",
    "]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gerar o dataframe e salvar\n",
    "df_previsao = df_previsao.astype(str)\n",
    "\n",
    "csv_buffer = io.StringIO()\n",
    "\n",
    "df_previsao.to_csv(csv_buffer, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': '18021D16F6CFBE0B',\n",
       "  'HostId': 'dd9025bab4ad464b049177c95eb6ebf374d3b3fd1af9251148b658df7ac2e3e8',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'accept-ranges': 'bytes',\n",
       "   'content-length': '0',\n",
       "   'etag': '\"e2cf99abace5783c34fd64aa3d099709\"',\n",
       "   'server': 'MinIO',\n",
       "   'strict-transport-security': 'max-age=31536000; includeSubDomains',\n",
       "   'vary': 'Origin, Accept-Encoding',\n",
       "   'x-amz-id-2': 'dd9025bab4ad464b049177c95eb6ebf374d3b3fd1af9251148b658df7ac2e3e8',\n",
       "   'x-amz-request-id': '18021D16F6CFBE0B',\n",
       "   'x-content-type-options': 'nosniff',\n",
       "   'x-ratelimit-limit': '2001',\n",
       "   'x-ratelimit-remaining': '2001',\n",
       "   'x-xss-protection': '1; mode=block',\n",
       "   'date': 'Sat, 26 Oct 2024 21:13:11 GMT'},\n",
       "  'RetryAttempts': 0},\n",
       " 'ETag': '\"e2cf99abace5783c34fd64aa3d099709\"'}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Salvando dados no bucket\n",
    "s3_client.put_object(Bucket=\"trusted\", Key=f'/previsao/{agora}.csv', Body=csv_buffer.getvalue(), ContentType='text/csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRUSTED PARADAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrar registros onde Categoria e Método = Posicao\n",
    "filtro_paradas = df[(df['Categoria'] == 'Parada') & (df['Métodos'] == 'BuscarParadasPorLinha')]\n",
    "\n",
    "# Criar o dicionário usando as colunas \"Chave\" e \"Nome Campo\"\n",
    "mapa_chaves_paradas = dict(zip(filtro_paradas['Chave'], filtro_paradas['Nome Campo']))\n",
    "\n",
    "dados_paradas_renomeados = renomear_chaves(dados_parada, mapa_chaves_paradas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para transformar o JSON renomeado em DataFrame\n",
    "def json_paradas_para_df(dados_renomeados):\n",
    "    paradas_lista = []\n",
    "    \n",
    "    # Percorre todas as sublistas no JSON\n",
    "    for sublista in dados_renomeados:\n",
    "        for parada in sublista:\n",
    "            paradas_lista.append(parada)\n",
    "    \n",
    "    # Criar o DataFrame com os dados das paradas\n",
    "    df_paradas = pd.DataFrame(paradas_lista)\n",
    "    return df_paradas\n",
    "\n",
    "# Transformar o JSON renomeado em DataFrame\n",
    "df_paradas = json_paradas_para_df(dados_paradas_renomeados)\n",
    "\n",
    "# Gerar o dataframe e salvar\n",
    "df_paradas = df_paradas.astype(str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': '18020A78774554CF',\n",
       "  'HostId': 'dd9025bab4ad464b049177c95eb6ebf374d3b3fd1af9251148b658df7ac2e3e8',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'accept-ranges': 'bytes',\n",
       "   'content-length': '0',\n",
       "   'etag': '\"67ffae4d8bee602f7501787431f23c3f\"',\n",
       "   'server': 'MinIO',\n",
       "   'strict-transport-security': 'max-age=31536000; includeSubDomains',\n",
       "   'vary': 'Origin, Accept-Encoding',\n",
       "   'x-amz-id-2': 'dd9025bab4ad464b049177c95eb6ebf374d3b3fd1af9251148b658df7ac2e3e8',\n",
       "   'x-amz-request-id': '18020A78774554CF',\n",
       "   'x-content-type-options': 'nosniff',\n",
       "   'x-ratelimit-limit': '2062',\n",
       "   'x-ratelimit-remaining': '2062',\n",
       "   'x-xss-protection': '1; mode=block',\n",
       "   'date': 'Sat, 26 Oct 2024 15:31:59 GMT'},\n",
       "  'RetryAttempts': 0},\n",
       " 'ETag': '\"67ffae4d8bee602f7501787431f23c3f\"'}"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_buffer = io.StringIO()\n",
    "\n",
    "df_paradas.to_csv(csv_buffer, index=False)\n",
    "\n",
    "# Salvando dados no bucket\n",
    "s3_client.put_object(Bucket=\"trusted\", Key=f'/paradas/{agora}.csv', Body=csv_buffer.getvalue(), ContentType='text/csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definindo os argumentos padrão para as tarefas do DAG\n",
    "default_args = {\n",
    "    'owner': 'airflow',\n",
    "    'depends_on_past': False,\n",
    "    'start_date': days_ago(1),\n",
    "    'email_on_failure': False,\n",
    "    'email_on_retry': False,\n",
    "    'retries': 1,\n",
    "}\n",
    "\n",
    "\n",
    "def inserir_dados_posicao():\n",
    "\n",
    "\n",
    "# Criando o DAG\n",
    "dag = DAG(\n",
    "    'raw_posicao',\n",
    "    default_args=default_args,\n",
    "    description='DAG para salvar dados brutos de posicao',\n",
    "    catchup=False,\n",
    "    schedule_interval= '*/30 * * * *' #'@hourly',\n",
    "    \n",
    ")\n",
    "\n",
    "# TESTE ALTERAção\n",
    " \n",
    "# Definindo a tarefa\n",
    "ingest_task = PythonOperator(\n",
    "    task_id='ingest_data',\n",
    "    python_callable=inserir_dados_posicao, # AQUI ONDE COLOCO A FUNÇÃO QUE A DAG VAI EXECUTAR\n",
    "    dag=dag,\n",
    ")\n",
    "\n",
    "# Definindo a ordem de execução das tarefas\n",
    "ingest_task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
